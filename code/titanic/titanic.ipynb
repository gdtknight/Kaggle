{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Titanic\n",
        "jupyter: python3\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "import numpy as np  # 넘파이 임포트\n",
        "import pandas as pd  # 판다스 임포트\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Predict survival on the Titanic and get familiar with ML basics\n",
        "\n",
        "## Data exploratary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "PROJECT_NAME = \"titanic\"\n",
        "\n",
        "def get_data_dir_path():\n",
        "    if (os.path.exists(\"/kaggle/input\")):\n",
        "        return (os.path.join(\"/kaggle/input\", PROJECT_NAME))\n",
        "    else:\n",
        "    \treturn (os.path.join(os.path.expanduser(\"~\"), \"dev\", \"kaggle\", \"input\", PROJECT_NAME))\n",
        "\n",
        "def get_output_dir_path():\n",
        "    if (os.path.exists(\"/kaggle/working\")):\n",
        "        return \"/kaggle/working\"\n",
        "    else:\n",
        "        return (os.path.join(os.path.expanduser(\"~\"), \"dev\", \"kaggle\", \"output\", PROJECT_NAME))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_path = get_data_dir_path()\n",
        "print(\"data_path =\", data_path) \n",
        "train = pd.read_csv(os.path.join(data_path, \"train.csv\"))  # 훈련 데이터\n",
        "test = pd.read_csv(os.path.join(data_path, \"test.csv\"))  # 테스트 데이터\n",
        "submission = pd.read_csv(os.path.join(data_path, \"gender_submission.csv\"))  # 제출 샘플 데이터"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train = train.drop(columns=[\"Name\"])\n",
        "\n",
        "def get_summary_df(origin: pd.DataFrame):\n",
        "    summary = pd.DataFrame(origin.dtypes, columns = ['데이터 타입'])\n",
        "    summary = summary.reset_index()\n",
        "    summary = summary.rename(columns = {'index':'피처'})\n",
        "    summary['결측값 개수'] = origin.isnull().sum().values\n",
        "    summary['고윳값 개수'] = origin.nunique().values\n",
        "    summary['첫번째 값'] = origin.loc[0].values\n",
        "    summary['두번째 값'] = origin.loc[1].values\n",
        "    summary['세번째 값'] = origin.loc[2].values\n",
        "    return (summary)\n",
        "    \n",
        "summary = get_summary_df(train)\n",
        "print(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cols = np.array(train.columns)\n",
        "print(cols)\n",
        "figure, axes = plt.subplots(nrows = 4, ncols = 2)\n",
        "# sns.histplot(x=\"Sex\",         y=\"Survived\", data=train, ax=axes[0, 0])\n",
        "# sns.histplot(x=\"Age\",         y=\"Survived\", data=train, ax=axes[0, 0])\n",
        "sns.countplot(x=\"Pclass\",   hue=\"Survived\", data=train, ax=axes[0, 0])\n",
        "sns.countplot(x=\"Sex\",      hue=\"Survived\", data=train, ax=axes[0, 1])\n",
        "sns.histplot(x=\"SibSp\",       y=\"Survived\", data=train, ax=axes[1, 0])\n",
        "sns.histplot(x=\"Parch\",       y=\"Survived\", data=train, ax=axes[1, 1])\n",
        "sns.histplot(x=\"Ticket\",      y=\"Survived\", data=train, ax=axes[2, 0])\n",
        "sns.histplot(x=\"Fare\",        y=\"Survived\", data=train, ax=axes[2, 1])\n",
        "sns.histplot(x=\"Cabin\",       y=\"Survived\", data=train, ax=axes[3, 0])\n",
        "# sns.histplot(x=\"Embarked\",  y=\"Survived\", data=train, ax=axes[3, 1])\n",
        "sns.countplot(x=\"Embarked\", hue=\"Survived\", data=train, ax=axes[3, 1])\n",
        "axes[0, 0].ylabels = [0, 1]\n",
        "axes[3, 0].tick_params(labelrotation=90)\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bins = [0, 10, 20, 30, 40, 50, 60, 80]  # 원하는 대로 조정\n",
        "labels = ['0-9','10-19','20-29','30-39','40-49','50-59','60+']\n",
        "\n",
        "train['AgeBin'] = pd.cut(train['Age'], bins=bins, labels=labels, right=False)\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.countplot(data=train, x='AgeBin', hue='Survived')\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bins   = [0, 10, 20, 30, 40, 50, 60, 80]\n",
        "labels = ['0s','10s','20s','30s','40s','50s','60+']\n",
        "\n",
        "train['AgeBin'] = pd.cut(train['Age'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# 연령대별 Survived=0,1 카운트\n",
        "age_counts = train.groupby(['AgeBin', 'Survived']).size().unstack(fill_value=0)\n",
        "# 컬럼 이름 정리 (선택)\n",
        "age_counts.columns = ['Died', 'Survived']  # 0=사망, 1=생존\n",
        "age_counts = age_counts.reset_index()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.lineplot(data=age_counts, x='AgeBin', y='Died', marker='o', label='Died')\n",
        "sns.lineplot(data=age_counts, x='AgeBin', y='Survived', marker='o', label='Survived')\n",
        "\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(train.columns)\n",
        "print(train.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(train.info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# print(train.columns)\n",
        "print(train.head())\n",
        "# print(test.columns)\n",
        "# print(test.info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "onehot_encoder = OneHotEncoder()\n",
        "\n",
        "encoded_embarked = onehot_encoder.fit_transform(train[[\"Embarked\"]])\n",
        "print(type(encoded_embarked))\n",
        "print(pd.DataFrame(encoded_embarked.toarray()))\n",
        "dummy = pd.get_dummies(train[[\"Embarked\"]])\n",
        "print(type(dummy))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 데이터 로드 (새로 로드하여 깨끗한 상태로 시작)\n",
        "train_processed = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
        "test_processed = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
        "\n",
        "print(\"Train shape:\", train_processed.shape)\n",
        "print(\"Test shape:\", test_processed.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 결측치 처리\n",
        "# Age: 중앙값으로 대체\n",
        "train_processed['Age'] = train_processed['Age'].fillna(train_processed['Age'].median())\n",
        "test_processed['Age'] = test_processed['Age'].fillna(test_processed['Age'].median())\n",
        "\n",
        "# Embarked: 최빈값으로 대체\n",
        "train_processed['Embarked'] = train_processed['Embarked'].fillna(train_processed['Embarked'].mode()[0])\n",
        "test_processed['Embarked'] = test_processed['Embarked'].fillna(test_processed['Embarked'].mode()[0])\n",
        "\n",
        "# Fare: 중앙값으로 대체\n",
        "test_processed['Fare'] = test_processed['Fare'].fillna(test_processed['Fare'].median())\n",
        "\n",
        "# Cabin: 결측값이 많으므로 있음/없음으로 변환\n",
        "train_processed['Cabin'] = train_processed['Cabin'].notna().astype(int)\n",
        "test_processed['Cabin'] = test_processed['Cabin'].notna().astype(int)\n",
        "\n",
        "print(\"결측치 처리 후 Train 결측값:\\n\", train_processed.isnull().sum())\n",
        "print(\"\\n결측치 처리 후 Test 결측값:\\n\", test_processed.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 새로운 피처 생성\n",
        "# FamilySize: 가족 구성원 수\n",
        "train_processed['FamilySize'] = train_processed['SibSp'] + train_processed['Parch'] + 1\n",
        "test_processed['FamilySize'] = test_processed['SibSp'] + test_processed['Parch'] + 1\n",
        "\n",
        "# IsAlone: 혼자 여행 여부\n",
        "train_processed['IsAlone'] = (train_processed['FamilySize'] == 1).astype(int)\n",
        "test_processed['IsAlone'] = (test_processed['FamilySize'] == 1).astype(int)\n",
        "\n",
        "print(\"새로운 피처 추가 완료\")\n",
        "print(train_processed[['SibSp', 'Parch', 'FamilySize', 'IsAlone']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 범주형 변수 인코딩\n",
        "# Sex: male=1, female=0\n",
        "train_processed['Sex'] = train_processed['Sex'].map({'male': 1, 'female': 0})\n",
        "test_processed['Sex'] = test_processed['Sex'].map({'male': 1, 'female': 0})\n",
        "\n",
        "# Embarked: One-Hot Encoding\n",
        "train_processed = pd.get_dummies(train_processed, columns=['Embarked'], prefix='Embarked')\n",
        "test_processed = pd.get_dummies(test_processed, columns=['Embarked'], prefix='Embarked')\n",
        "\n",
        "# 사용하지 않을 컬럼 제거\n",
        "drop_cols = ['PassengerId', 'Name', 'Ticket']\n",
        "train_processed = train_processed.drop(columns=drop_cols)\n",
        "\n",
        "# test에서는 PassengerId를 나중에 사용하므로 따로 저장\n",
        "test_ids = test_processed['PassengerId']\n",
        "test_processed = test_processed.drop(columns=drop_cols)\n",
        "\n",
        "print(\"전처리 완료!\")\n",
        "print(\"Train shape:\", train_processed.shape)\n",
        "print(\"Test shape:\", test_processed.shape)\n",
        "print(\"\\nTrain columns:\", train_processed.columns.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 학습 데이터 준비\n",
        "X = train_processed.drop('Survived', axis=1)\n",
        "y = train_processed['Survived']\n",
        "\n",
        "print(\"Features:\", X.columns.tolist())\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Random Forest 모델 생성 및 학습\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_model.fit(X, y)\n",
        "\n",
        "# Cross Validation 점수 확인\n",
        "cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy')\n",
        "print(f\"Cross Validation Scores: {cv_scores}\")\n",
        "print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Feature Importance 시각화\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
        "plt.title('Feature Importance - Random Forest')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction and Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 테스트 데이터로 예측\n",
        "predictions = rf_model.predict(test_processed)\n",
        "\n",
        "# 제출 파일 생성\n",
        "submission_df = pd.DataFrame({\n",
        "    'PassengerId': test_ids,\n",
        "    'Survived': predictions\n",
        "})\n",
        "\n",
        "print(\"Predictions sample:\")\n",
        "print(submission_df.head(10))\n",
        "print(f\"\\nTotal predictions: {len(submission_df)}\")\n",
        "print(f\"Survived: {(predictions == 1).sum()}, Died: {(predictions == 0).sum()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 제출 파일 저장\n",
        "output_dir = get_output_dir_path()\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "output_path = os.path.join(output_dir, \"submission.csv\")\n",
        "submission_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Submission file saved to: {output_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/yoshin/.pyenv/versions/42/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}